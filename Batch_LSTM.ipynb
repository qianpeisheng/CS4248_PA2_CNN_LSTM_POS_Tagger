{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBlog post:\\nTaming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health:\\nhttps://medium.com/@_willfalcon/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\"\"\"\n",
    "Blog post:\n",
    "Taming LSTMs: Variable-sized mini-batches and why PyTorch is good for your health:\n",
    "https://medium.com/@_willfalcon/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'an', 'Oct.', '19', 'review', 'of', '``', 'The', 'Misanthrope', \"''\", 'at', 'Chicago', \"'s\", 'Goodman', 'Theatre', '(', '``', 'Revitalized', 'Classics', 'Take', 'the', 'Stage', 'in', 'Windy', 'City', ',', \"''\", 'Leisure', '&', 'Arts', ')', ',', 'the', 'role', 'of', 'Celimene', ',', 'played', 'by', 'Kim', 'Cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'Christina', 'Haag', '.']\n",
      "['IN', 'DT', 'NNP', 'CD', 'NN', 'IN', '``', 'DT', 'NN', \"''\", 'IN', 'NNP', 'POS', 'NNP', 'NNP', '-LRB-', '``', 'VBN', 'NNS', 'VBP', 'DT', 'NN', 'IN', 'NNP', 'NNP', ',', \"''\", 'NN', 'CC', 'NNS', '-RRB-', ',', 'DT', 'NN', 'IN', 'NNP', ',', 'VBN', 'IN', 'NNP', 'NNP', ',', 'VBD', 'RB', 'VBN', 'TO', 'NNP', 'NNP', '.']\n",
      "39832 39832\n"
     ]
    }
   ],
   "source": [
    "# change the data structure to be [sent, tag]\n",
    "def load_one_line(line):\n",
    "    line_split_by_space = line.split()\n",
    "    sent = []\n",
    "    tag = []\n",
    "    for item in line_split_by_space:\n",
    "        item_split = item.split(\"/\")\n",
    "        if len(item_split) > 2:\n",
    "            item_combine = item_split[0]\n",
    "            for i in range(1, len(item_split) - 1):\n",
    "                item_combine = item_combine + '/' + item_split[i]\n",
    "            sent.append(item_combine)\n",
    "            tag.append(item_split[i + 1])\n",
    "        else:\n",
    "            sent.append(item_split[0])\n",
    "            tag.append(item_split[1])\n",
    "    return (sent, tag)\n",
    "\n",
    "def load_train_file(train_file):\n",
    "    train_sents = []\n",
    "    train_tags = []\n",
    "    with open(train_file) as infile:\n",
    "        for line in infile:\n",
    "            train_sent, train_tag = load_one_line(line)\n",
    "            train_sents.append(train_sent)\n",
    "            train_tags.append(train_tag)\n",
    "    return (train_sents, train_tags)\n",
    "train_sents, train_tags = load_train_file('sents.train')\n",
    "print(train_sents[0])\n",
    "print(train_tags[0])\n",
    "print(len(train_sents), len(train_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12646, 18]\n",
      "1\n",
      "23769\n",
      "46\n",
      "{0: '<PAD>', 1: 'IN', 2: 'DT', 3: 'NNP', 4: 'CD', 5: 'NN', 6: '``', 7: \"''\", 8: 'POS', 9: '-LRB-', 10: 'VBN', 11: 'NNS', 12: 'VBP', 13: ',', 14: 'CC', 15: '-RRB-', 16: 'VBD', 17: 'RB', 18: 'TO', 19: '.', 20: 'VBZ', 21: 'NNPS', 22: 'PRP', 23: 'PRP$', 24: 'VB', 25: 'JJ', 26: 'MD', 27: 'VBG', 28: 'RBR', 29: ':', 30: 'WP', 31: 'WDT', 32: 'JJR', 33: 'PDT', 34: 'RBS', 35: 'WRB', 36: 'JJS', 37: '$', 38: 'RP', 39: 'FW', 40: 'EX', 41: 'SYM', 42: '#', 43: 'LS', 44: 'UH', 45: 'WP$'}\n"
     ]
    }
   ],
   "source": [
    "#build word to index, tag to index\n",
    "# unknown threshold = 1\n",
    "word_to_index_count = {}\n",
    "tag_to_index = {'<PAD>': 0}\n",
    "for sent, tags in zip(train_sents, train_tags):\n",
    "    for word, tag in zip(sent, tags):\n",
    "        if word not in word_to_index_count:\n",
    "            word_to_index_count[word] = [len(word_to_index_count),1]\n",
    "        else:\n",
    "            word_to_index_count[word][1] += 1\n",
    "        if tag not in tag_to_index:\n",
    "            tag_to_index[tag] = len(tag_to_index)\n",
    "\n",
    "print(word_to_index_count['nice'])\n",
    "print(tag_to_index['IN'])\n",
    "\n",
    "word_to_index = {'<PAD>': 0, '<UNK>': 1}\n",
    "for word, index_count in word_to_index_count.items():\n",
    "    if index_count[1] > 1:\n",
    "        word_to_index[word] = len(word_to_index)\n",
    "print(len(word_to_index))\n",
    "# build reverse\n",
    "index_to_tag = {v:k for k,v in tag_to_index.items()}\n",
    "print(len(tag_to_index))\n",
    "print(index_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "max_length = 150\n",
    "b = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BieberLSTM(nn.Module):\n",
    "    def __init__(self, nb_layers, nb_lstm_units=50, embedding_dim=32, batch_size=b):\n",
    "        super(BieberLSTM, self).__init__()\n",
    "        self.to(device)\n",
    "        self.on_gpu = True\n",
    "        self.vocab = word_to_index\n",
    "        self.tags = tag_to_index\n",
    "\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # don't count the padding tag for the classifier output\n",
    "        self.nb_tags = len(self.tags)\n",
    "\n",
    "        # when the model is bidirectional we double the output dimension\n",
    "        #self.lstm\n",
    "\n",
    "        # build actual NN\n",
    "        self.__build_model()\n",
    "\n",
    "    def __build_model(self):\n",
    "        # build embedding layer first\n",
    "        nb_vocab_words = len(self.vocab)\n",
    "\n",
    "        # whenever the embedding sees the padding index it'll make the whole vector zeros\n",
    "        padding_idx = self.vocab['<PAD>']\n",
    "        self.word_embedding = nn.Embedding(\n",
    "            num_embeddings=nb_vocab_words,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=padding_idx\n",
    "        )\n",
    "\n",
    "        # design LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            num_layers=self.nb_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional = True, \n",
    "            dropout = 0.5\n",
    "        )\n",
    "\n",
    "        # output layer which projects back to tag space\n",
    "        self.hidden_to_tag = nn.Linear(self.nb_lstm_units * 2, self.nb_tags)\n",
    "    \n",
    "    def change_batch_size(self, x):\n",
    "        self.batch_size = x\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(self.nb_layers * 2, self.batch_size, self.nb_lstm_units)\n",
    "        hidden_b = torch.randn(self.nb_layers * 2, self.batch_size, self.nb_lstm_units)\n",
    "\n",
    "        if self.on_gpu:\n",
    "            hidden_a = hidden_a.cuda()\n",
    "            hidden_b = hidden_b.cuda()\n",
    "\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        return (hidden_a, hidden_b)\n",
    "\n",
    "    def forward(self, X, X_lengths):\n",
    "        # reset the LSTM hidden state. Must be done before you run a new batch. Otherwise the LSTM will treat\n",
    "        # a new batch as a continuation of a sequence\n",
    "        self.hidden = self.init_hidden()\n",
    "        #print('x size', X.size())\n",
    "\n",
    "        batch_size, seq_len = X.size()\n",
    "\n",
    "        # ---------------------\n",
    "        # 1. embed the input\n",
    "        # Dim transformation: (batch_size, seq_len, 1) -> (batch_size, seq_len, embedding_dim)\n",
    "        X = self.word_embedding(X)\n",
    "        #print(X.shape, 'X')\n",
    "\n",
    "        # ---------------------\n",
    "        # 2. Run through RNN\n",
    "        # TRICK 2 ********************************\n",
    "        # Dim transformation: (batch_size, seq_len, embedding_dim) -> (batch_size, seq_len, nb_lstm_units)\n",
    "\n",
    "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        X_lengths = torch.tensor([X_lengths]* self.batch_size, dtype=torch.long).to(device)\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
    "\n",
    "        # now run through LSTM\n",
    "        X, self.hidden = self.lstm(X, self.hidden)\n",
    "\n",
    "        # undo the packing operation\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "\n",
    "        # ---------------------\n",
    "        # 3. Project to tag space\n",
    "        # Dim transformation: (batch_sBieberLSTMize, seq_len, nb_lstm_units) -> (batch_size * seq_len, nb_lstm_units)\n",
    "\n",
    "        # this one is a bit tricky as well. First we need to reshape the data so it goes into the linear layer\n",
    "        X = X.contiguous()\n",
    "        X = X.view(-1, X.shape[2])\n",
    "\n",
    "        # run through actual linear layer\n",
    "        X = self.hidden_to_tag(X)\n",
    "\n",
    "        # ---------------------\n",
    "        # 4. Create softmax activations bc we're doing classification\n",
    "        # Dim transformation: (batch_size * seq_len, nb_lstm_units) -> (batch_size, seq_len, nb_tags)\n",
    "        X = F.log_softmax(X, dim=1)\n",
    "\n",
    "        # I like to reshape for mental sanity so we're back to (batch_size, seq_len, nb_tags)\n",
    "        X = X.view(batch_size, seq_len, self.nb_tags)\n",
    "\n",
    "        Y_hat = X\n",
    "        return Y_hat\n",
    "\n",
    "    def loss(self, Y_hat, Y, X_lengths):\n",
    "        # TRICK 3 ********************************\n",
    "        # before we calculate the negative log likelihood, we need to mask out the activations\n",
    "        # this means we don't want to take into account padded items in the output vector\n",
    "        # simplest way to think about this is to flatten ALL sequences into a REALLY long sequence\n",
    "        # and calculate the loss on that.\n",
    "\n",
    "        # flatten all the labels\n",
    "        Y = Y.view(-1)\n",
    "\n",
    "        # flatten all predictions\n",
    "        Y_hat = Y_hat.view(-1, self.nb_tags)\n",
    "        #print(Y_hat.shape[0],Y_hat.shape[1], 'Y_hat.shape')\n",
    "\n",
    "        # create a mask by filtering out all tokens that ARE NOT the padding token\n",
    "        tag_pad_token = self.tags['<PAD>']\n",
    "        mask = (Y > tag_pad_token).float()\n",
    "        #print('mask', mask, mask.shape)\n",
    "\n",
    "        # count how many tokens we have\n",
    "        nb_tokens = int(torch.sum(mask).data[0])\n",
    "        #print('nb tokens', nb_tokens)\n",
    "\n",
    "        # pick the values for the label and zero out the rest with the mask\n",
    "        #print(Y_hat, Y, mask, '?')\n",
    "        #print(Y_hat.size())\n",
    "        Y_hat = Y_hat[range(Y_hat.shape[0]), Y] * mask\n",
    "        #print(Y_hat, 'New Y_hat')\n",
    "        # compute cross entropy loss which ignores all <PAD> tokens\n",
    "        ce_loss = -torch.sum(Y_hat) / nb_tokens\n",
    "\n",
    "        return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch\n",
      "tensor(3.8241, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:136: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1  epoch\n",
      "tensor(1.0571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2  epoch\n",
      "tensor(0.8048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3  epoch\n",
      "tensor(0.5052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "4  epoch\n",
      "tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "5  epoch\n",
      "decrease lr\n",
      "tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "6  epoch\n",
      "tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "7  epoch\n",
      "tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "8  epoch\n",
      "decrease lr further\n",
      "tensor(0.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "9  epoch\n",
      "tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1465, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(sents, d, is_target):\n",
    "    sents_indexes = []\n",
    "    for sent in sents:\n",
    "        sent_indexes = []\n",
    "        for w in sent:\n",
    "            if w in d:\n",
    "                sent_indexes.append(d[w])\n",
    "            else:\n",
    "                sent_indexes.append(d['<UNK>'])\n",
    "        # print(len(sent_indexes), 'len sent indexes')\n",
    "        if not is_target:\n",
    "            sent_indexes += [d['<PAD>']] * (max_length - len(sent_indexes))\n",
    "        sents_indexes.append(sent_indexes)\n",
    "    return torch.tensor(sents_indexes, dtype=torch.long).to(device)\n",
    "\n",
    "model = BieberLSTM(2) # 1 layer\n",
    "model.to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay = 0.0005)\n",
    "    \n",
    "for epoch in range(10):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    print(epoch, ' epoch')\n",
    "    #print('epoch', epoch)\n",
    "    # train with batch size 32\n",
    "    if epoch == 5:\n",
    "        print('decrease lr')\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = 0.01\n",
    "    if epoch == 8:\n",
    "        print('decrease lr further')\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = 0.001\n",
    "    for i in range(int(len(train_sents)/b)): # 39832/50 ~= 796.64 / 32 ~= 124x\n",
    "        #print(i)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        start = i * b\n",
    "        sents = train_sents[start:start + b]\n",
    "        tags = train_tags[start:start + b]\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sents, word_to_index, False)\n",
    "        targets = prepare_sequence(tags, tag_to_index, False)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in, max_length)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = model.loss(tag_scores, targets, max_length)\n",
    "        if i % 500 == 0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I/PRP have/VBP an/DT apple/NN '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_sent(sent):\n",
    "    sent = sent.split()\n",
    "    with torch.no_grad():\n",
    "        inputs = prepare_sequence([sent] * b, word_to_index, False)\n",
    "        #print(inputs)\n",
    "        #model.change_batch_size(1)\n",
    "        tag_scores = model(inputs, max_length)\n",
    "        #print(tag_scores)\n",
    "        val, tag_indexes = torch.max(tag_scores[0], 1)\n",
    "        tag_names = [index_to_tag[i.item()] for i in tag_indexes]\n",
    "    output = ''\n",
    "    for word, tag in zip(sent, tag_names):\n",
    "        output += word + '/' + tag + ' '\n",
    "    return output\n",
    "tag_sent('I have an apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "def tag_and_save(test_file, out):\n",
    "    sents = []\n",
    "    with open(test_file) as t:\n",
    "        for line in t:\n",
    "            sents.append(line)\n",
    "    with open(out, 'w') as o:\n",
    "        for sent in sents:\n",
    "            o.write(tag_sent(sent) + '\\n')\n",
    "    print('Finished.')\n",
    "tag_and_save('sents.test', 'sents.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.946423697856528\n"
     ]
    }
   ],
   "source": [
    "def eval():\n",
    "    reader = open('sents.out')\n",
    "    out_lines = reader.readlines()\n",
    "    reader.close()\n",
    "\n",
    "    reader = open('sents.answer')\n",
    "    ref_lines = reader.readlines()\n",
    "    reader.close()\n",
    "\n",
    "    if len(out_lines) != len(ref_lines):\n",
    "        print('Error: No. of lines in output file and reference file do not match.')\n",
    "        exit(0)\n",
    "\n",
    "    total_tags = 0\n",
    "    matched_tags = 0\n",
    "    for i in range(0, len(out_lines)):\n",
    "        cur_out_line = out_lines[i].strip()\n",
    "        cur_out_tags = cur_out_line.split(' ')\n",
    "        cur_ref_line = ref_lines[i].strip()\n",
    "        cur_ref_tags = cur_ref_line.split(' ')\n",
    "        total_tags += len(cur_ref_tags)\n",
    "\n",
    "        for j in range(0, len(cur_ref_tags)):\n",
    "            if cur_out_tags[j] == cur_ref_tags[j]:\n",
    "                matched_tags += 1\n",
    "\n",
    "    print(\"Accuracy=\", float(matched_tags) / total_tags)\n",
    "eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
